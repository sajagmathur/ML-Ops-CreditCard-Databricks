{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5dbe683-f6e8-4a22-947a-0dc1e80b0e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3481eeb1-c649-440d-b606-c575001d6520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f3a52c8-fc27-4a35-81c0-eef66fd2a026",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "963b2f8e-ece2-4472-a1b1-eb7d0b96b412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import mlflow\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, ClassificationPreset\n",
    "from evidently import Dataset, DataDefinition\n",
    "from evidently import BinaryClassification\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e125c638-d18d-4278-b92c-3b4198f94214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load credentials from environment variables\n",
    "\n",
    "SNOWFLAKE_ACCOUNT = dbutils.widgets.get(\"SNOWFLAKE_ACCOUNT\")\n",
    "SNOWFLAKE_USER = dbutils.widgets.get(\"SNOWFLAKE_USER\")\n",
    "SNOWFLAKE_PASSWORD = dbutils.widgets.get(\"SNOWFLAKE_PASSWORD\")\n",
    "SNOWFLAKE_WAREHOUSE = dbutils.widgets.get(\"SNOWFLAKE_WAREHOUSE\")\n",
    "SNOWFLAKE_DATABASE = dbutils.widgets.get(\"SNOWFLAKE_DATABASE\")\n",
    "SNOWFLAKE_SCHEMA = dbutils.widgets.get(\"SNOWFLAKE_SCHEMA\")\n",
    "EMAIL = dbutils.widgets.get(\"DATABRICKS_EMAIL\")\n",
    "\n",
    "\n",
    "# Optional: set them as environment variables if you need\n",
    "\n",
    "os.environ[\"SNOWFLAKE_USER\"] = SNOWFLAKE_USER\n",
    "os.environ[\"SNOWFLAKE_PASSWORD\"] = SNOWFLAKE_PASSWORD\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = SNOWFLAKE_ACCOUNT\n",
    "os.environ[\"SNOWFLAKE_WAREHOUSE\"] = SNOWFLAKE_WAREHOUSE\n",
    "os.environ[\"SNOWFLAKE_DATABASE\"] = SNOWFLAKE_DATABASE\n",
    "os.environ[\"EMAIL\"] = EMAIL\n",
    "os.environ[\"DATABRICKS_SCHEMA\"] = SNOWFLAKE_SCHEMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f367b00d-a50c-4e46-a6bc-3a5ff779b4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Paths for Databricks workspace\n",
    "MONITORING_DIR = f\"/Workspace/Users/{EMAIL}/CREDITCARD/Monitoring\"\n",
    "RETRAIN_DECISION_DIR = f\"/Workspace/Users/{EMAIL}/CREDITCARD/Retraining_Decision\"\n",
    "CHAMPION_MODEL_PATH = f\"/Workspace/Users/{EMAIL}/CREDITCARD/Champion_Model/champion_model.pkl\"\n",
    "\n",
    "# MLflow setup\n",
    "mlflow.set_tracking_uri(os.getenv(\"MLFLOW_TRACKING_URI\", \"databricks\"))\n",
    "mlflow.set_experiment(f\"/Users/{EMAIL}/Monitoring_Experiments_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29c088c4-306b-460e-9420-6f82f1c02dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_from_snowflake(query):\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=SNOWFLAKE_USER,\n",
    "        password=SNOWFLAKE_PASSWORD,\n",
    "        account=SNOWFLAKE_ACCOUNT,\n",
    "        warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "        database=SNOWFLAKE_DATABASE,\n",
    "        schema=SNOWFLAKE_SCHEMA\n",
    "    )\n",
    "    df = conn.cursor().execute(query).fetch_pandas_all()\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a4e9ec2-2710-4da0-9b35-cc0255e27ed4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_champion_model():\n",
    "    if not os.path.exists(CHAMPION_MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Champion model not found at {CHAMPION_MODEL_PATH}\")\n",
    "    with open(CHAMPION_MODEL_PATH, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"✅ Loaded champion model from {CHAMPION_MODEL_PATH}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfcd55c1-9342-4e1a-95fe-1cc8e8e76710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1_Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"MatthewsCorrcoef\": matthews_corrcoef(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed057fcb-138a-479e-92b3-ac1e4cb0ea5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load model\n",
    "    model = load_champion_model()\n",
    "\n",
    "    # Fetch reference and current datasets from Snowflake\n",
    "    ref_query = f\"SELECT * FROM CREDITCARD_REFERENCE.PUBLIC.CREDITCARD_REFERENCE\"\n",
    "    cur_query = f\"SELECT * FROM {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.CREDITCARD_BATCH_INPUTS\"\n",
    "\n",
    "    ref = fetch_from_snowflake(ref_query)\n",
    "    cur = fetch_from_snowflake(cur_query)\n",
    "\n",
    "    target = \"CLASS\"\n",
    "    # Define features (exclude IDs, target, and prediction columns)\n",
    "    exclude_cols = {'ID', 'CLASS', 'PREDICTION', 'PREDICTION_PROB'}\n",
    "    feature_cols = [c for c in ref.columns if c not in exclude_cols]\n",
    "\n",
    "    # Convert feature columns to numeric safely\n",
    "    ref[feature_cols] = ref[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    cur[feature_cols] = cur[feature_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Predict using the champion model\n",
    "    ref[\"prediction\"] = model.predict(ref[feature_cols])\n",
    "    cur[\"prediction\"] = model.predict(cur[feature_cols])\n",
    "\n",
    "    # Define Evidently data definition for binary classification\n",
    "    dd = DataDefinition(\n",
    "        classification=[BinaryClassification(target=target, prediction_labels=\"prediction\")],\n",
    "        categorical_columns=[target, \"prediction\"]\n",
    "    )\n",
    "\n",
    "    ds_ref = Dataset.from_pandas(ref, data_definition=dd)\n",
    "    ds_cur = Dataset.from_pandas(cur, data_definition=dd)\n",
    "\n",
    "    # Build and run report for data drift and classification metrics\n",
    "    report = Report(metrics=[DataDriftPreset(), ClassificationPreset()])\n",
    "    result = report.run(reference_data=ds_ref, current_data=ds_cur)\n",
    "\n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(MONITORING_DIR, exist_ok=True)\n",
    "    os.makedirs(RETRAIN_DECISION_DIR, exist_ok=True)\n",
    "\n",
    "    # Save Evidently HTML report\n",
    "    report_path = os.path.join(MONITORING_DIR, \"evidently_report.html\")\n",
    "    result.save_html(report_path)\n",
    "    print(f\"✅ Evidently report saved: {report_path}\")\n",
    "\n",
    "    # Calculate metrics for retraining decision\n",
    "    ref_metrics = calc_metrics(ref[target], ref[\"prediction\"])\n",
    "    cur_metrics = calc_metrics(cur[target], cur[\"prediction\"])\n",
    "\n",
    "    # Retraining decision threshold: 10% degradation on key metrics\n",
    "    degraded = []\n",
    "    threshold = 0.10\n",
    "    for metric in [\"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\"]:\n",
    "        if ref_metrics.get(metric) is not None and cur_metrics.get(metric) is not None:\n",
    "            if ref_metrics[metric] - cur_metrics[metric] > threshold:\n",
    "                degraded.append(metric)\n",
    "\n",
    "    decision = \"YES\" if degraded else \"NO\"\n",
    "    rationale = f\"Threshold: 10% degradation. Degraded metrics: {', '.join(degraded)}\" if degraded else \"All metrics within threshold.\"\n",
    "\n",
    "    # Save retraining decision as CSV\n",
    "    retrain_path = os.path.join(RETRAIN_DECISION_DIR, \"Retrain.csv\")\n",
    "    pd.DataFrame({\n",
    "        \"Retraining_Decision\": [decision],\n",
    "        \"Rationale\": [rationale]\n",
    "    }).to_csv(retrain_path, index=False)\n",
    "    print(f\"✅ Retraining decision saved: {retrain_path}\")\n",
    "\n",
    "    # Log artifacts and metrics to MLflow\n",
    "    with mlflow.start_run(run_name=\"Monitoring_Champion\") as run:\n",
    "        mlflow.log_artifact(report_path)\n",
    "        mlflow.log_artifact(retrain_path)\n",
    "        for k, v in cur_metrics.items():\n",
    "            mlflow.log_metric(f\"Current_{k}\", v)\n",
    "        for k, v in ref_metrics.items():\n",
    "            mlflow.log_metric(f\"Reference_{k}\", v)\n",
    "        mlflow.set_tag(\"Retrain_Decision\", decision)\n",
    "        mlflow.set_tag(\"Rationale\", rationale)\n",
    "        mlflow.set_tag(\"Model_Stage\", \"Production\")\n",
    "        mlflow.set_tag(\"Model_Role\", \"Champion\")\n",
    "\n",
    "    print(\"✅ Monitoring run completed, artifacts logged to MLflow.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b92ef63-202b-496f-a963-e3f31d4963ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "monitor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
