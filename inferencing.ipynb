{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77e22013-3e13-4e8c-a688-f6ff3b79a64f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e08ef2-e72b-4f24-baef-5ee0b6434b97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f97c1945-78ab-480d-9f35-ac66cf825ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import io\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import snowflake.connector\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf0d140-050c-438f-b452-7dae5f15b119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Snowflake credentials from env\n",
    "SNOWFLAKE_ACCOUNT = os.getenv('SNOWFLAKE_ACCOUNT')\n",
    "SNOWFLAKE_USER = os.getenv('SNOWFLAKE_USER')\n",
    "SNOWFLAKE_PASSWORD = os.getenv('SNOWFLAKE_PASSWORD')\n",
    "SNOWFLAKE_WAREHOUSE = os.getenv('SNOWFLAKE_WAREHOUSE')\n",
    "SNOWFLAKE_DATABASE = os.getenv('SNOWFLAKE_DATABASE')\n",
    "SNOWFLAKE_SCHEMA = os.getenv('SNOWFLAKE_SCHEMA')\n",
    "\n",
    "# Databricks workspace paths\n",
    "DATABRICKS_EMAIL = os.getenv(\"DATABRICKS_EMAIL\")\n",
    "PREDICTION_DIR = f\"/Workspace/Users/{DATABRICKS_EMAIL}/CREDITCARD/Predictions\"\n",
    "CHAMPION_MODEL_DIR = f\"/Workspace/Users/{DATABRICKS_EMAIL}/CREDITCARD/Champion_Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f1e9b2-eccd-4f99-83fe-01983d94ad3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MLflow model name in Unity Catalog (must be 3-part: catalog.schema.name)\n",
    "UC_MODEL_NAME = \"workspace.default.CreditCardFraudModel\"\n",
    "\n",
    "# Snowflake tables\n",
    "BATCH_INPUT_TABLE = f\"{SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.CREDITCARD_BATCH_INPUTS\"\n",
    "BATCH_PREDICTIONS_TABLE = f\"{SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.BATCH_PREDICTIONS\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24fe42b0-0369-453c-a4e9-5ae8405e4ca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_snowflake_connection():\n",
    "    return snowflake.connector.connect(\n",
    "        user=SNOWFLAKE_USER,\n",
    "        password=SNOWFLAKE_PASSWORD,\n",
    "        account=SNOWFLAKE_ACCOUNT,\n",
    "        warehouse=SNOWFLAKE_WAREHOUSE,\n",
    "        database=SNOWFLAKE_DATABASE,\n",
    "        schema=SNOWFLAKE_SCHEMA\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d20f405f-5267-44a8-952f-ab38857a3f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_batch_data():\n",
    "    print(f\"üì• Fetching batch input data from Snowflake: {BATCH_INPUT_TABLE}\")\n",
    "    with get_snowflake_connection() as conn:\n",
    "        df = pd.read_sql(f\"SELECT * FROM {BATCH_INPUT_TABLE}\", conn)\n",
    "        print(f\"‚úÖ Loaded {df.shape[0]} rows, {df.shape[1]} columns.\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68c28208-29c0-4d62-b0eb-ae8d1a5d4d21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_champion_model():\n",
    "    print(f\"üîç Looking for champion model in UC: {UC_MODEL_NAME}\")\n",
    "    mlflow.set_tracking_uri(\"databricks\")\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Search all versions\n",
    "    versions = client.search_model_versions(f\"name='{UC_MODEL_NAME}'\")\n",
    "\n",
    "    # Get the one tagged as production and role=champion\n",
    "    for v in versions:\n",
    "        full_version = client.get_model_version(name=UC_MODEL_NAME, version=v.version)\n",
    "        tags = full_version.tags\n",
    "        if tags.get(\"status\") == \"production\" and tags.get(\"role\") == \"champion\":\n",
    "            print(f\"üèÜ Champion model found: Version {v.version}, Run ID: {v.run_id}\")\n",
    "            model_uri = f\"models:/{UC_MODEL_NAME}/{v.version}\"\n",
    "            return mlflow.sklearn.load_model(model_uri), model_uri\n",
    "\n",
    "    raise Exception(\"‚ùå No champion model (status=production, role=champion) found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2644488f-b0f1-4a6d-868e-316f2de30179",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_predictions(df, model):\n",
    "    # Ensure ID column exists\n",
    "    if 'ID' not in df.columns:\n",
    "        df.insert(0, 'ID', range(1, len(df) + 1))\n",
    "\n",
    "    features = df.drop(columns=['ID'] + (['CLASS'] if 'CLASS' in df.columns else []))\n",
    "\n",
    "    print(f\"üîÆ Generating predictions for {features.shape[0]} records...\")\n",
    "    preds = model.predict(features)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(features)[:, 1]\n",
    "    else:\n",
    "        probs = [None] * len(preds)\n",
    "\n",
    "    result_df = df.copy()\n",
    "    result_df['PREDICTION'] = preds\n",
    "    result_df['PREDICTION_PROB'] = probs\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886b217c-3cb7-455a-8b89-e7536e59ff57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions_to_snowflake(df):\n",
    "    print(f\"üßæ Inserting predictions into Snowflake: {BATCH_PREDICTIONS_TABLE}\")\n",
    "    with get_snowflake_connection() as conn:\n",
    "        cursor = conn.cursor()\n",
    "        try:\n",
    "            cursor.execute(f\"TRUNCATE TABLE {BATCH_PREDICTIONS_TABLE}\")\n",
    "            conn.commit()\n",
    "\n",
    "            cols = list(df.columns)\n",
    "            placeholders = ', '.join(['%s'] * len(cols))\n",
    "            insert_query = f\"INSERT INTO {BATCH_PREDICTIONS_TABLE} ({', '.join(cols)}) VALUES ({placeholders})\"\n",
    "            data = [tuple(row) for row in df.to_numpy()]\n",
    "            cursor.executemany(insert_query, data)\n",
    "            conn.commit()\n",
    "            print(\"‚úÖ Predictions written to Snowflake.\")\n",
    "        finally:\n",
    "            cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563e78a8-366a-48f8-b844-a602b6931a04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions_to_databricks(df, path):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    file_path = os.path.join(path, \"batch_predictions.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"üíæ Predictions saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "915fa894-6281-4507-854c-b89e9084187c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def copy_champion_model_to_workspace(model_uri):\n",
    "    # Download artifacts\n",
    "    local_model_path = mlflow.artifacts.download_artifacts(model_uri)\n",
    "    model_pkl_path = os.path.join(local_model_path, \"model.pkl\")\n",
    "\n",
    "    if not os.path.exists(model_pkl_path):\n",
    "        raise FileNotFoundError(\"‚ùå model.pkl not found in downloaded artifacts.\")\n",
    "\n",
    "    os.makedirs(CHAMPION_MODEL_DIR, exist_ok=True)\n",
    "    dst_path = os.path.join(CHAMPION_MODEL_DIR, \"champion_model.pkl\")\n",
    "    shutil.copy(model_pkl_path, dst_path)\n",
    "    print(f\"üì¶ Champion model copied to: {dst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7531f125-1a9e-4cdf-ae16-efec4f466412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"üöÄ Starting batch inference pipeline\")\n",
    "\n",
    "    # 1. Load batch input data\n",
    "    batch_df = fetch_batch_data()\n",
    "\n",
    "    # 2. Load champion model from UC\n",
    "    model, model_uri = get_champion_model()\n",
    "\n",
    "    # 3. Generate predictions\n",
    "    predictions_df = generate_predictions(batch_df, model)\n",
    "\n",
    "    # 4. Save to Snowflake (truncate first)\n",
    "    save_predictions_to_snowflake(predictions_df)\n",
    "\n",
    "    # 5. Save predictions locally on Databricks\n",
    "    save_predictions_to_databricks(predictions_df, PREDICTION_DIR)\n",
    "\n",
    "    # 6. Copy model.pkl to Databricks workspace\n",
    "    copy_champion_model_to_workspace(model_uri)\n",
    "\n",
    "    print(\"‚úÖ Batch inference completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a459af3-28b7-4c6a-a239-acdf186d90ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "inferencing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
